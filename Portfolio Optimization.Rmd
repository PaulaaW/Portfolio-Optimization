---
title: "Portfolio Optimization"
output: html_notebook
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Abstract
The project is intended to optimize a portfolio that contains growth stocks, and interpret the optimized portfolio(s) through efficient frontier. It will also predict the future performance of the optimized portfolio and the market index using the Monte Carlo stimulation. By comparing the forecasted returns, we found that the portfolio's return has a the possibility to outperform the market index in the next 30 days. However, the predicted results are somewhat off compare to the real price data. This might because of the special post-pandemic timing, further study may include event study and behavioral finance to improve the model. 

### Introduction
The world's economy has performed poorly in the past year due to the pandemic, and lots of industries were affected by it. The year 2020 started strong, then the whole stock market experienced large shock when the pandemic first started in February, and was gradually recovering to the previous level during the summer. The market index S&P 500 has turned down almost 65% in March and finished the year up with 14% from the last year's level. Looking deeper into the growth stocks performance last year, people had high expectations for them because more people and work were moved online. Growth stocks(mainly technology stocks) are also the ones that carried the bear market back to normal, and also outperformed both the market and value stocks. Knowing this, we will construct a portfolio with growth stocks and optimize it based on its past performance. We will also forecast the return of the optimized portfolio to see if it still can outperform the market in the next 30 days. There are some analysts shifted their favor from growth stock to value stock, because they believe people are getting back to normal after vaccine came out, and the growth stock won't be as popular as last year. 


### Methods
The investment risk can be reduced and return can be maximized by applying portfolio optimization. The measurement indexes used in this process include: standard deviation, log returns, covariance matrix, and sharpe ratio. Standard deviation are used to estimate stocks' risk because the more volatile the stock price is, the more risk is associated with it. If a stock has a large standard deviation, that means the stock's price changes in a wide range and is risky.   The sharpe ratio is calculated as the return divided by risk, assume a zero risk free return here. It represents how much return is receiving for bearing one percent of the risk. Therefore, the higher sharpe ratio, the more effective the investment is. All these measurements will give us an overall insight of the stock prices, and the next step is to predict the future portfolio performance.

To forecast the future performance of the portfolio, we will use Monte Carlo Stimulation. It will take the stocks' past risk and return as reference, to predict the portfolio's return as a whole. 

Next, we will look at more details and go through the methods and codes that are used in this project. 

```{r}
library(plotly)
library(timetk)
library(tidyverse)
library(ggplot2)
library(broom)
library(dplyr)
```

```{r}
if (!require("quantmod")) {
    install.packages("quantmod")
    library(quantmod)
}
```

```{r}
start <- as.Date("2020-03-21")
end <- as.Date("2021-03-21")
```

```{r}
# Portfolio Components: Netflix, Paypal, Shopify, Google, Facebook, Alibaba
getSymbols("NFLX", src = "yahoo", from = start, to = end)
getSymbols("PYPL", src = "yahoo", from = start, to = end)
getSymbols("SHOP", src = "yahoo", from = start, to = end)
getSymbols("GOOGL", src = "yahoo", from = start, to = end)
getSymbols("FB", src = "yahoo", from = start, to = end)
getSymbols("BABA", src = "yahoo", from = start, to = end)
NFLX <- NFLX[, "NFLX.Close"]
PYPL <- PYPL[, "PYPL.Close"]
SHOP <- SHOP[, "SHOP.Close"]
GOOGL <- GOOGL[, "GOOGL.Close"]
FB <- FB[, "FB.Close"]
BABA <- BABA[, "BABA.Close"]
```

```{r}
#Combine all the closed stock prices together
stocks <- cbind(NFLX,PYPL,SHOP,GOOGL,FB,BABA)
head(stocks)
```

The codes above imported six stocks close price data (Netflix, Paypal, Shopify, Google, Facebook, Alibaba) from Yahoo.Finance and combined them all into one dataframe. The data is range from 3/21/2020 - 3/21/2021, and has a one year range in total. 

```{r}
#Compute the daily log return
stocks_change = stocks %>% log %>% diff
head(stocks_change)
```

```{r}
#Compute column means and covariance matrix
mean_change <- colMeans(stocks_change, na.rm=TRUE)
print(round(mean_change,5))
```

Then we compute the daily log returns. Log returns are frequently used in Finance. A lognormal distribution should be created when there is a need to calculate continuously compounded returns. The values within the distribution are always positive and future stock price generated from it will always be positive as well.(Because the stock price cannot fall below zero) The first row is NA because it doesn't have any row ahead of it, so the calculation won't generate any result. We also compute the average daily returns here which is the column means of the daily return for each stock.

```{r}
#Compute covariance matrix
cov_mat <- cov(stocks_change[-c(1),]) * 252
print(round(cov_mat,4))
```

Covariance matrix is calculated from the daily stock returns, it gets rid of the first row that contains no value and annualized it.(There are about 252 trading days each year) It can show the degree of correlations of different stocks' annual return. Typically, the correlations among stocks in the portfolio are expected to be low. The more diverse is the stocks, the less risky is the portfolio. When there are unexpected downturns in one stock, it won't affect other stocks in the portfolio by much.

```{r}
#Assign random numbers between 0 and 1 to each stocks
set.seed(1)
tick <- c('NFLX', 'PYPL', 'SHOP', 'GOOGL', 'FB', 'BABA')
wts <- runif(n = length(tick))
print(wts)
```

```{r}
#Shift the randomly assigned numbers into weights for different stocks
wts2 <- wts/sum(wts)
print(wts2)
```

```{r}
#Calculate the annualized portfolio return given the new weights
port_returns <- (sum(wts2 * mean_change) + 1)^252 - 1
port_returns
```

```{r}
#Calculate the portfolio risk by a series of matrix multiplications
port_risk <- sqrt(t(wts2) %*% (cov_mat %*% wts2))
print(port_risk)
```

```{r}
# Calculate the sharpe ratio using the return and risk calculated above
sharpe_ratio <- port_returns/port_risk
print(sharpe_ratio)
```

The code above asked the system to randomly generate numbers between 0 and 1 to each stocks. Next, we reform these random numbers into weights of the portfolio.(that can sum up to 1) Using the new weights created, we'll calculate the annualized portfolio return by multiplying the weights by average daily returns and minus one(the original investment) in the end. The portfolio risk is calculated by the squre root of transpose of weights * (covariance matrix*weights). The "covariance matrix times weights" gives the average daily stock returns under the different weights, and the square root of the transpose of the weights times the result of it reduce the dimension of the matrix and therefore 

```{r}
num_port <- 5000
```

```{r}
#Weights of all the randomly generated portfolio
all_wts <- matrix(nrow = num_port,
                  ncol = length(tick))
```

```{r}
#Returns of all the randomly generated portfolio
port_returns <- vector('numeric', length = num_port)
```

```{r}
#Risk of all the randomly generated portfolio
port_risk <- vector('numeric', length = num_port)
```

```{r}
#Sharpe ratio all the randomly generated portfolio
sharpe_ratio <- vector('numeric', length = num_port)
```

```{r}
for (i in seq_along(port_returns)) {
  
  wts <- runif(length(tick))
  wts <- wts/sum(wts)
  
  # Storing weight in the matrix
  all_wts[i,] <- wts
  
  # Portfolio returns
  
  port_ret <- sum(wts * mean_change)
  port_ret <- ((port_ret + 1)^252) - 1
  
  # Storing Portfolio Returns values
  port_returns[i] <- port_ret
  
  
  # Creating and storing portfolio risk
  port_sd <- sqrt(t(wts) %*% (cov_mat  %*% wts))
  port_risk[i] <- port_sd
  
  # Creating and storing Portfolio Sharpe Ratios
  # Assuming 0% Risk free rate
  
  sr <- port_ret/port_sd
  sharpe_ratio[i] <- sr
  
}
```

```{r}
# Storing the values in the table
portfolio_values <- tibble(Return = port_returns,
                  Risk = port_risk,
                  SharpeRatio = sharpe_ratio)


# Converting matrix to a tibble and changing column names
all_wts <- tk_tbl(all_wts)
```

```{r}
colnames(all_wts) <- colnames(stocks_change)

# Combing all the values together
portfolio_values <- tk_tbl(cbind(all_wts, portfolio_values))
```

```{r}
head(portfolio_values)
```

```{r}
min_var <- portfolio_values[which.min(portfolio_values$Risk),]
max_sr <- portfolio_values[which.max(portfolio_values$SharpeRatio),]
```

```{r}
min_var
```

```{r}
max_sr
```

```{r}
p <- portfolio_values %>%
  ggplot(aes(x = Risk, y = Return, color = SharpeRatio)) +
  geom_point(size=0.5) +
  theme_classic() +
  scale_y_continuous(labels = scales::percent) +
  scale_x_continuous(labels = scales::percent) +
  labs(x = 'Annualized Risk',
       y = 'Annualized Returns',
       title = "Portfolio Optimization & Efficient Frontier") +
  geom_point(aes(x = Risk,
                 y = Return), data = min_var, color = 'red') +
  geom_point(aes(x = Risk,
                 y = Return), data = max_sr, color = 'red') +
  annotate('text', x = 0.34, y = 0.50, label = "Minimum variance portfolio") +
  annotate('text', x = 0.35, y = 1.54, label = "Tangency Portfolio") 

ggplotly(p)
```

```{r}
Portfolio_prices <- NFLX*0.2144948 + PYPL*0.01176868 + SHOP*0.03982831 + GOOGL*0.391175 + FB*0.04915577 + BABA*0.2935774
head(Portfolio_prices)
```

```{r}
stocks_series = tidy(Portfolio_prices) %>% 
  
  ggplot(aes(x=index,y=value)) + geom_line()

stocks_series
```

```{r}
mc_rep = 1000 # Number of Monte Carlo Simulations
training_days = 30 
```

```{r}
# This function returns the first differences of a t x q matrix of data
returns = function(Y){
  len = nrow(Y)
  yDif = unclass(Y[2:len, ]) / unclass(Y[1:len-1, ]) - 1
}

# Get the Stock Returns
stock_Returns = returns(stocks)
head(stock_Returns)
```

```{r}
# Get the Variance Covariance Matrix of Stock Returns
coVarMat = cov(stock_Returns)
miu = colMeans(stock_Returns)
# Extend the vector to a matrix
Miu = matrix(rep(miu, training_days), nrow = 6)
```

```{r}
#Take the generated minimum variance portfolio
vector1 <- c(0.2144948,0.01176868,0.03982831,0.391175,0.04915577,0.2935774)
portfolio_Weights <- array(c(vector1),dim = c(1,6))
portfolio_Weights
```

```{r}
# Initializing simulated 30 day portfolio returns
portfolio_Returns_30_m = matrix(0, training_days, mc_rep)

set.seed(200)
for (i in 1:mc_rep) {
  Z = matrix ( rnorm( dim(stock_Returns)[2] * training_days ), ncol = training_days )
  # Lower Triangular Matrix from our Choleski Factorization
  L = t( chol(coVarMat) )
  # Calculate stock returns for each day
  daily_Returns = Miu + L %*% Z  
  # Calculate portfolio returns for 30 days
  portfolio_Returns_30 = cumprod( portfolio_Weights %*% daily_Returns + 1 )
  # Add it to the monte-carlo matrix
  portfolio_Returns_30_m[,i] = portfolio_Returns_30;
}
```

```{r}
# Visualising result
x_axis = rep(1:training_days, mc_rep)
y_axis = as.vector(portfolio_Returns_30_m-1)
plot_data = data.frame(x_axis, y_axis)
ggplot(data = plot_data, aes(x = x_axis, y = y_axis)) + geom_path(col = 'red', size = 0.1) +
  xlab('Days') + ylab('Portfolio Returns') + 
  ggtitle('Simulated Portfolio Returns in 30 days')+
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
Avg_Portfolio_Returns = mean(portfolio_Returns_30_m[30,]-1)
SD_Portfolio_Returns = sd(portfolio_Returns_30_m[30,]-1)
Median_Portfolio_Returns = median(portfolio_Returns_30_m[30,]-1)
print(c(Avg_Portfolio_Returns,SD_Portfolio_Returns,Median_Portfolio_Returns))
```

```{r}
Avg_CI = quantile(portfolio_Returns_30_m[30,]-1, c(0.025, 0.975))
print(Avg_CI)
```


```{r}
getSymbols("SPY", src = "yahoo", from = start, to = end)
SPY <- SPY[, "SPY.Close"]
```

```{r}
SPY_Return = returns(SPY)
head(SPY_Return)
```

```{r}
# Get the Variance Covariance Matrix of Stock Returns
coVarMat = cov(SPY_Return)
miu2 = colMeans(SPY_Return)
# Extend the vector to a matrix
Miu2 = matrix(rep(miu2, training_days), nrow = 1)
```

```{r}
# Initializing simulated 30 day portfolio returns
SPY_Returns_30_m = matrix(0, training_days, mc_rep)

set.seed(200)
for (i in 1:mc_rep) {
  Z = matrix ( rnorm( dim(SPY_Return)[2] * training_days ), ncol = training_days )
  # Lower Triangular Matrix from our Choleski Factorization
  L = t( chol(coVarMat2) )
  # Calculate stock returns for each day
  daily_Returns = Miu2 + L %*% Z  
  # Calculate portfolio returns for 30 days
  SPY_Returns_30 = cumprod( 1 %*% daily_Returns + 1 )
  # Add it to the monte-carlo matrix
  SPY_Returns_30_m[,i] = SPY_Returns_30;
}
```

```{r}
# Visualising result
x_axis = rep(1:training_days, mc_rep)
y_axis = as.vector(SPY_Returns_30_m-1)
plot_data = data.frame(x_axis, y_axis)
ggplot(data = plot_data, aes(x = x_axis, y = y_axis)) + geom_path(col = 'red', size = 0.1) +
  xlab('Days') + ylab('SPY Returns') + 
  ggtitle('Simulated SPY Returns in 30 days')+
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
Avg_SPY_Returns = mean(SPY_Returns_30_m[30,]-1)
SD_SPY_Returns = sd(SPY_Returns_30_m[30,]-1)
Median_SPY_Returns = median(SPY_Returns_30_m[30,]-1)
print(c(Avg_SPY_Returns,SD_SPY_Returns,Median_SPY_Returns))
```

```{r}
Avg_CI = quantile(SPY_Returns_30_m[30,]-1, c(0.025, 0.975))
print(Avg_CI)
```


Reference
https://www.investopedia.com/articles/investing/102014/lognormal-and-normal-distribution.asp

https://israeldi.github.io/bookdown/_book/monte-carlo-simulation-of-stock-portfolio-in-r-matlab-and-python.html

https://www.forbes.com/advisor/investing/stock-market-year-in-review-2020/












